{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eaabde7-93f6-4b71-bdde-e30971c9e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=8-iWF2sPaHT6IIdnziKgFhouNsgYnDAIy3npwVIpdzQ&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=8-iWF2sPaHT6IIdnziKgFhouNsgYnDAIy3npwVIpdzQ&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AX4XfWgvWVDcgSxMC83OIaHjI2oYhzwbrZVK9DQmfr2wfb8d85Pl27_Gv8U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import tensorflow\n",
    "import ee\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# import custom module\n",
    "import ALR_functions_server_side as alr\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e892d60-c553-47e0-a064-081754d36cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# order of bands from SL2P output:\n",
    "# 00-11: 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', \n",
    "# 12-19: 'AOT', 'WVP', 'SCL', 'TCI_R', 'TCI_G', 'TCI_B', 'MSK_CLDPRB', 'MSK_SNWPRB', \n",
    "# 20-26: 'QA10', 'QA20', 'QA60', 'date', 'cosVZA', 'cosSZA', 'cosRAA', \n",
    "# 27-32: 'estimateLAI', 'partition', 'networkID', 'errorLAI', 'partition_1', 'networkID_1'\n",
    "\n",
    "outputName = 'LAI'\n",
    "\n",
    "# define input image\n",
    "testImage = ee.Image('users/kateharvey/scaled_image')\n",
    "inputImage = ee.Image(testImage.select(1,2,3,7,22,23,27,28,29,30,31,32))\n",
    "inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'QA60', 'date', 'estimateLAI', 'partition', 'networkID', 'errorLAI', 'partition_1', 'networkID_1'])\n",
    "\n",
    "# name bands of inputImage and scale response band\n",
    "inputImage = inputImage.rename(inputImage_bands)\n",
    "\n",
    "inputImage = inputImage.addBands(inputImage.select('estimateLAI').divide(1000), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68e5d5b-496d-4ee3-b538-160c97963471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Below we define a list of strings representing the expressions for each vegetation index as a function of the bands in the input image\n",
    "# More vegetation indices can be defined, but the list CANNOT contain any two vegetation indices which are a linear combination of each\n",
    "# other or LARs will fail to select the requested number of variables\n",
    "\n",
    "# The formatting of the expression must be\n",
    "# \"<name of VI> = <expression with band names from inputImage_bands used as variables in the form b('<band name>')\"\n",
    "\n",
    "# Only include VIs that use 10 m bands (B2, B3, B4, B8)\n",
    "input_VI_definition = ee.List([\"RAW_B2  = b('B2')\",\n",
    "                               \"RAW_B3  = b('B3')\",\n",
    "                               \"RAW_B4  = b('B4')\",\n",
    "                               \"RAW_B8  = b('B8')\",\n",
    "                               \"GI      = b('B3')/b('B4')\",\n",
    "                             # \"RVI3    = b('B4')/b('B6')\",\n",
    "                             # \"SR3     = b('B5')/b('B4')\",\n",
    "                             # \"GM1     = b('B6')/b('B3')\",\n",
    "                             # \"GM2     = b('B6')/b('B5')\",\n",
    "                             # \"SR2     = b('B7')/b('B3')\",\n",
    "                             # \"PSSR    = b('B7')/b('B4')\",\n",
    "                               \"SGI     = b('B8')/b('B4')\",\n",
    "                             # \"MSI     = b('B11')/b('B7')\",\n",
    "                             # \"II      = b('B11')/b('B12')\",\n",
    "                               \"GVI     = (b('B8')/b('B3'))-1\",\n",
    "                             # \"PSRI    = (b('B4')-b('B3'))/b('B6')\",\n",
    "                               \"NDVI3   = ((b('B8')-b('B4'))/(b('B8')))+b('B4')\",\n",
    "                             # \"SR5     = 1/b('B5')\",\n",
    "                             # \"SR6     = b('B4')/(b('B3')*b('B5'))\",\n",
    "                             # \"SR7     = b('B8')/(b('B3')*b('B5'))\",\n",
    "                             # \"IPVI    = b('B7')/(b('B7')+b('B4'))\",\n",
    "                             # \"ARI     = (1/b('B3'))-(1/b('B5'))\",\n",
    "                             # \"ARI2    = b('B7')*((1/b('B3'))-(1/b('B5')))\",\n",
    "                               \"NDVI    = (b('B8')-b('B4'))/(b('B8')+b('B4'))\",\n",
    "                               \"GNDVI   = (b('B8')-b('B3'))/(b('B8')+b('B3'))\",\n",
    "                             # \"NDWI    = (b('B8')-b('B11'))/(b('B8')+b('B11'))\",\n",
    "                             # \"NDREVI  = (b('B8')-b('B5'))/(b('B8')+b('B5'))\",\n",
    "                               \"NDGI    = (b('B3')-b('B4'))/(b('B3')+b('B4'))\",\n",
    "                             # \"NDI1    = (b('B7')-b('B5'))/(b('B7')-b('B4'))\",\n",
    "                             # \"NDI2    = (b('B8')-b('B5'))/(b('B8')-b('B4'))\",\n",
    "                             # \"RENDVI  = (b('B6')-b('B5'))/(b('B6')+b('B5'))\",\n",
    "                             # \"OSAVI   = (1.16*(b('B7')-b('B4')))/(b('B7')+b('B4')+0.61)\",\n",
    "                             # \"NMDI    = (b('B8')-(b('B11')-b('B12')))/(b('B8')+(b('B11')-b('B12')))\",\n",
    "                             # \"HI      = ((b('B3')-b('B5'))/(b('B3')+b('B5')))-0.5*b('B5')\",\n",
    "                             # \"GVSP    = (-0.283*b('B3') - 0.66*b('B4') + 0.577*b('B6') + 0.388*b('B8'))/(0.433*b('B3') - 0.632*b('B4') + 0.586*b('B6') + 0.264*b('B8A'))\",\n",
    "                             # \"MCARI   = ((b('B5')-b('B4'))-0.2*(b('B5')-b('B3')))*(b('B5')/b('B4'))\",\n",
    "                             # \"TCARI   = 3*((b('B5')-b('B4'))-0.2*(b('B5')-b('B3'))*(b('B5')/b('B4')))\",\n",
    "                               \"EVI     = 2.5*((b('B8')-b('B4'))/(b('B8')+6*b('B4')-7.5*b('B3')+1))\",\n",
    "                               \"EVI2    = 2.5*((b('B8')-b('B4'))/(b('B8')+2.4*b('B4')+1))\",\n",
    "                               \"RDVI    = (b('B8')-b('B4'))/((b('B8')+b('B4'))**0.5)\",\n",
    "                               \"MSR     = ((b('B8')/b('B4'))-1)/((b('B8')/b('B4'))**0.5+1)\",\n",
    "                             # \"MSAVI   = 0.5*(2*b('B7')+1-((2*b('B7')+1)**2-8*(b('B7')-b('B4')))**0.5)\",\n",
    "                               \"MSAVI2  = 0.5*(2*b('B8')+1-((2*b('B8')+1)**2-8*(b('B8')-b('B4')))**0.5)\",\n",
    "                             # \"MCARI2  = (1.5*(2.5*(b('B7')-b('B4'))-1.3*(b('B7')-b('B3'))))/((((2*b('B7')+1)**2)-(6*b('B7')-5*(b('B4')**0.5))-0.5)**0.5)\",\n",
    "                             # \"MTVI2   = (1.5*(1.2*(b('B7')-b('B3'))-2.5*(b('B4')-b('B3'))))/(((2*b('B7')+1)**2-(6*b('B7')-5*b('B4'))-0.5)**0.5)\",\n",
    "                             # \"MSR2    = ((b('B7')/b('B4'))-1)/(((b('B7')/b('B4'))+1)**0.5)\",\n",
    "                               \"NLI     = ((b('B8')**2)-b('B4'))/((b('B8')**2)+b('B4'))\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acde569c-061e-48ef-883e-42b80cdbd39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputImage = alr.format_image(inputImage, inputImage_bands, 'estimateLAI', input_VI_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1191bf2-40df-49a3-8fd6-a3b37dbe6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_pixels = alr.get_num_pixels(inputImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f361ff-efd9-40f1-8572-579b56fefd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledImage = alr.scale_image(inputImage, 'estimateLAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a0db16-229c-4888-a96b-0df66f3ba6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of bands to pass to ee_LARS function (only want Sentinel 2 bands and VIs)\n",
    "inputBand_names = ['B2', 'B3', 'B4', 'B8', 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI',\n",
    "                   'GNDVI', 'NDGI', 'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c35dadeb-74d6-4073-8d77-54659a068716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  ['GVI', 'MSR', 'RDVI', 'NDGI', 'B8']\n"
     ]
    }
   ],
   "source": [
    "select_features = ee.List(alr.ee_LARS(scaledImage, inputBand_names, 'estimateLAI', 5, 10000)).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d6dc3f-2d9e-4d0a-9241-feb6b1b283b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmedCollection = alr.trim_data(image=inputImage.updateMask(inputImage.select('estimateLAI').gt(0)),\n",
    "                                  selected_features=select_features,\n",
    "                                  response_band='estimateLAI',\n",
    "                                  num_samples=5000,\n",
    "                                  num_partitions=10)\n",
    "\n",
    "exportData = ee.batch.Export.table.toDrive(collection=trimmedCollection,\n",
    "                                           description='image_samples',\n",
    "                                           fileFormat='CSV')\n",
    "\n",
    "exportData.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be92e9d-a5a2-4619-8528-a871c2e38c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY\n",
      "RUNNING\n",
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# Essentially a wait loop to see if the data has finished exporting by checking with the server-side\n",
    "prev_task_status = ee.data.getTaskStatus(exportData.id)[0][\"state\"]\n",
    "print(prev_task_status)\n",
    "while exportData.active():\n",
    "    task_status = ee.data.getTaskStatus(exportData.id)[0][\"state\"]\n",
    "    if(task_status != prev_task_status):\n",
    "        print(task_status)\n",
    "    prev_task_status = task_status\n",
    "    time.sleep(5)\n",
    "print(ee.data.getTaskStatus(exportData.id)[0][\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0b5188-eba2-47c9-846b-1dacea0d2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = ee.FeatureCollection(\"users/hemitshah/nnet5\")\n",
    "nnet_inputs = nnet.filter(ee.Filter.eq(\"layer_num\", 0)).first()\n",
    "num_inputs = nnet_inputs.getNumber(\"num_nodes\")\n",
    "\n",
    "selected_features = nnet_inputs.getString(\"activation\").split(\",\")\n",
    "\n",
    "nnet = nnet.filterBounds(ee.Geometry.Point([0,0]))\n",
    "layer_list = nnet.sort(\"layer_num\").toList(nnet.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc3f1b7-49e2-4914-b961-5e153e4dd37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(ee.List(neural_net.get(0)).get(0))\\nprint(ee.List(neural_net.get(0)).get(1))\\nprint(ee.List(neural_net.get(1)).get(0))\\nprint(ee.List(neural_net.get(1)).get(1))\\nprint(ee.List(neural_net.get(2)).get(0))\\nprint(ee.List(neural_net.get(2)).get(1))\\nprint(ee.List(neural_net.get(3)).get(0))\\nprint(ee.List(neural_net.get(3)).get(1))\\nprint(ee.List(neural_net.get(4)).get(0))\\nprint(ee.List(neural_net.get(4)).get(1))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net = layer_list.map(alr.parse_layer)\n",
    "\n",
    "'''\n",
    "print(ee.List(neural_net.get(0)).get(0))\n",
    "print(ee.List(neural_net.get(0)).get(1))\n",
    "print(ee.List(neural_net.get(1)).get(0))\n",
    "print(ee.List(neural_net.get(1)).get(1))\n",
    "print(ee.List(neural_net.get(2)).get(0))\n",
    "print(ee.List(neural_net.get(2)).get(1))\n",
    "print(ee.List(neural_net.get(3)).get(0))\n",
    "print(ee.List(neural_net.get(3)).get(1))\n",
    "print(ee.List(neural_net.get(4)).get(0))\n",
    "print(ee.List(neural_net.get(4)).get(1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03c8fc8-c070-4fed-9f3b-0f65e279b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = inputImage.select('estimateLAI')\n",
    "nnet_inputs = scaledImage.select(selected_features)\n",
    "# layer1out = apply_nnet(neural_net.get(0), nnet_inputs)\n",
    "# layer2out = apply_nnet(neural_net.get(1), layer1out)\n",
    "# layer3out = apply_nnet(neural_net.get(2), layer2out)\n",
    "# layer4out = apply_nnet(neural_net.get(3), layer3out)\n",
    "# layer5out = apply_nnet(neural_net.get(4), layer4out)\n",
    "# Map.addLayer(layer1out)\n",
    "# Map.addLayer(layer2out)\n",
    "# Map.addLayer(layer3out)\n",
    "# Map.addLayer(layer4out)\n",
    "# Map.addLayer(layer5out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65831a8-7a0c-42f1-837e-560faf75eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = ee.Image(neural_net.iterate(alr.apply_nnet, nnet_inputs)).rename(\"NNET\")\n",
    "inputsCollection = ee.FeatureCollection(\"users/hemitshah/image_data_samples\").select(selected_features.add(\"LAI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9020b44-6733-410b-8d77-137daa344083",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_regressor = ee.Classifier.smileRandomForest(numberOfTrees=100,\n",
    "                                               variablesPerSplit=0,\n",
    "                                               minLeafPopulation=3,\n",
    "                                               bagFraction=0.1, seed=0).setOutputMode(\"REGRESSION\")\\\n",
    "                .train(features=inputsCollection, classProperty=\"LAI\", inputProperties=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48f456b3-74ac-4741-8635-b2c1423478f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_prediction = nnet_inputs.addBands(validation_data).classify(ee_regressor, \"RANDOM_FOREST\")\n",
    "# Map.addLayer(validation_data)\n",
    "# Map.addLayer(prediction_data)\n",
    "# Map.addLayer(ee_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709f9640-0003-43f4-8638-3998da2dba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_rmse = prediction_data.subtract(validation_data).pow(2).reduceRegion(ee.Reducer.mean(), None, None, None, None, True, 10000000, 1).values().getNumber(0).pow(0.5)\n",
    "rf_rmse = ee_prediction.subtract(validation_data).pow(2).reduceRegion(ee.Reducer.mean(), None, None, None, None, True, 10000000, 1).values().getNumber(0).pow(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331ea47-74ac-4960-b490-1336b6ae2b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
