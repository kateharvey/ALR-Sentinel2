{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import scipy\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import tensorflow\n",
    "import ee\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Set the test image using an uploaded asset for now\n",
    "testImage = ee.Image('users/kateharvey/TestImage')\n",
    "inputImage = ee.Image(testImage.select(1,2,3,7,23,27,28,29,30,31,32,33))\n",
    "\n",
    "# Change variable name here to match band name pattern (one of: Albedo, fAPAR, fCOVER, LAI, CCC, CWC, DASF)\n",
    "outputName = 'LAI'\n",
    "defaultBand = ee.String('estimate'+outputName)\n",
    "\n",
    "# List the bands that we expect in the image (ensure number of bands in the list below matches the number bands in the input image)\n",
    "# This is the order of bands produced by running SL2P10 and exporting the resulting ImageCollection\n",
    "inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'date', 'QC', 'estimateLAI', 'partition', 'networkID', 'errorLAI', 'partition_1', 'networkID_1'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Below we define a list of strings representing the expressions for each vegetation index as a function of the bands in the input image\n",
    "# More vegetation indices can be defined, but the list CANNOT contain any two vegetation indices which are a linear combination of each\n",
    "# other or LARs will fail to select the requested number of variables\n",
    "\n",
    "# The formatting of the expression must be\n",
    "# \"<name of VI> = <expression with band names from inputImage_bands used as variables in the form b('<band name>')\"\n",
    "\n",
    "# Only include VIs that use 10 m bands (B2, B3, B4, B8)\n",
    "input_VI_definition = ee.List([\"RAW_B2  = b('B2')\",\n",
    "                               \"RAW_B3  = b('B3')\",\n",
    "                               \"RAW_B4  = b('B4')\",\n",
    "                               \"RAW_B8  = b('B8')\",\n",
    "                               \"GI      = b('B3')/b('B4')\",\n",
    "                             # \"RVI3    = b('B4')/b('B6')\",\n",
    "                             # \"SR3     = b('B5')/b('B4')\",\n",
    "                             # \"GM1     = b('B6')/b('B3')\",\n",
    "                             # \"GM2     = b('B6')/b('B5')\",\n",
    "                             # \"SR2     = b('B7')/b('B3')\",\n",
    "                             # \"PSSR    = b('B7')/b('B4')\",\n",
    "                               \"SGI     = b('B8')/b('B4')\",\n",
    "                             # \"MSI     = b('B11')/b('B7')\",\n",
    "                             # \"II      = b('B11')/b('B12')\",\n",
    "                               \"GVI     = (b('B8')/b('B3'))-1\",\n",
    "                             # \"PSRI    = (b('B4')-b('B3'))/b('B6')\",\n",
    "                               \"NDVI3   = ((b('B8')-b('B4'))/(b('B8')))+b('B4')\",\n",
    "                             # \"SR5     = 1/b('B5')\",\n",
    "                             # \"SR6     = b('B4')/(b('B3')*b('B5'))\",\n",
    "                             # \"SR7     = b('B8')/(b('B3')*b('B5'))\",\n",
    "                             # \"IPVI    = b('B7')/(b('B7')+b('B4'))\",\n",
    "                             # \"ARI     = (1/b('B3'))-(1/b('B5'))\",\n",
    "                             # \"ARI2    = b('B7')*((1/b('B3'))-(1/b('B5')))\",\n",
    "                               \"NDVI    = (b('B8')-b('B4'))/(b('B8')+b('B4'))\",\n",
    "                               \"GNDVI   = (b('B8')-b('B3'))/(b('B8')+b('B3'))\",\n",
    "                             # \"NDWI    = (b('B8')-b('B11'))/(b('B8')+b('B11'))\",\n",
    "                             # \"NDREVI  = (b('B8')-b('B5'))/(b('B8')+b('B5'))\",\n",
    "                               \"NDGI    = (b('B3')-b('B4'))/(b('B3')+b('B4'))\",\n",
    "                             # \"NDI1    = (b('B7')-b('B5'))/(b('B7')-b('B4'))\",\n",
    "                             # \"NDI2    = (b('B8')-b('B5'))/(b('B8')-b('B4'))\",\n",
    "                             # \"RENDVI  = (b('B6')-b('B5'))/(b('B6')+b('B5'))\",\n",
    "                             # \"OSAVI   = (1.16*(b('B7')-b('B4')))/(b('B7')+b('B4')+0.61)\",\n",
    "                             # \"NMDI    = (b('B8')-(b('B11')-b('B12')))/(b('B8')+(b('B11')-b('B12')))\",\n",
    "                             # \"HI      = ((b('B3')-b('B5'))/(b('B3')+b('B5')))-0.5*b('B5')\",\n",
    "                             # \"GVSP    = (-0.283*b('B3') - 0.66*b('B4') + 0.577*b('B6') + 0.388*b('B8'))/(0.433*b('B3') - 0.632*b('B4') + 0.586*b('B6') + 0.264*b('B8A'))\",\n",
    "                             # \"MCARI   = ((b('B5')-b('B4'))-0.2*(b('B5')-b('B3')))*(b('B5')/b('B4'))\",\n",
    "                             # \"TCARI   = 3*((b('B5')-b('B4'))-0.2*(b('B5')-b('B3'))*(b('B5')/b('B4')))\",\n",
    "                               \"EVI     = 2.5*((b('B8')-b('B4'))/(b('B8')+6*b('B4')-7.5*b('B3')+1))\",\n",
    "                               \"EVI2    = 2.5*((b('B8')-b('B4'))/(b('B8')+2.4*b('B4')+1))\",\n",
    "                               \"RDVI    = (b('B8')-b('B4'))/((b('B8')+b('B4'))**0.5)\",\n",
    "                               \"MSR     = ((b('B8')/b('B4'))-1)/((b('B8')/b('B4'))**0.5+1)\",\n",
    "                             # \"MSAVI   = 0.5*(2*b('B7')+1-((2*b('B7')+1)**2-8*(b('B7')-b('B4')))**0.5)\",\n",
    "                               \"MSAVI2  = 0.5*(2*b('B8')+1-((2*b('B8')+1)**2-8*(b('B8')-b('B4')))**0.5)\",\n",
    "                             # \"MCARI2  = (1.5*(2.5*(b('B7')-b('B4'))-1.3*(b('B7')-b('B3'))))/((((2*b('B7')+1)**2)-(6*b('B7')-5*(b('B4')**0.5))-0.5)**0.5)\",\n",
    "                             # \"MTVI2   = (1.5*(1.2*(b('B7')-b('B3'))-2.5*(b('B4')-b('B3'))))/(((2*b('B7')+1)**2-(6*b('B7')-5*b('B4'))-0.5)**0.5)\",\n",
    "                             # \"MSR2    = ((b('B7')/b('B4'))-1)/(((b('B7')/b('B4'))+1)**0.5)\",\n",
    "                               \"NLI     = ((b('B8')**2)-b('B4'))/((b('B8')**2)+b('B4'))\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def format_image(image, image_bands, response_band, VI_definition):\n",
    "    image = ee.Image(image)\n",
    "    image_bands = ee.List(image_bands)\n",
    "    response_band = ee.String(response_band)\n",
    "    VI_definition = ee.List(VI_definition)\n",
    "    \n",
    "    # image_bands specifices a list of the names of the bands used in defining the expressions for VIs in VI_definition\n",
    "    image = image.rename(image_bands).toDouble()\n",
    "    \n",
    "    # Generate an imageCollection from a list of expressions defining a set of Vegetation Indices using the bands available in the image\n",
    "    VIimageCollection = ee.ImageCollection(VI_definition.map(lambda expr: image.expression(ee.String(expr))))\n",
    "    VIimage = VIimageCollection.toBands().regexpRename('[0-9]+_', '')\n",
    "    \n",
    "    # Reordering the bands in the image so the response band is the last band in the image\n",
    "    feature_bands = image_bands.remove(response_band)\n",
    "    \n",
    "    return image.select(feature_bands).addBands(VIimage).addBands(image.select(response_band))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "inputImage = format_image(inputImage, inputImage_bands, defaultBand, input_VI_definition)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_num_pixels(image):\n",
    "    # Retrieve the dimensions of the image from the metadata of the first band\n",
    "    image_dimensions = ee.List(image.getInfo()['bands'][0]['dimensions'])\n",
    "    image_height = image_dimensions.getNumber(0)\n",
    "    image_width = image_dimensions.getNumber(1)\n",
    "    image_pixels = image_height.multiply(image_width)\n",
    "    \n",
    "    return image_pixels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "num_input_pixels = get_num_pixels(inputImage)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def scale_image(image, response_band):\n",
    "    image = ee.Image(image)\n",
    "    response_band = ee.String(response_band)\n",
    "    image_pixels = ee.Number(get_num_pixels(image))\n",
    "    \n",
    "    # Setting up lists containing the input/feature bands in the image\n",
    "    bandList = image.bandNames()\n",
    "    featureList = bandList.remove(response_band)\n",
    "    num_bands = bandList.length()\n",
    "    num_features = featureList.length()\n",
    "    \n",
    "    # We will be using the reduceRegion() function on images from Earth Engine, \n",
    "    # which will process up to a specified number of pixels from the image to generate the outputs of the reducer\n",
    "    max_pixels = image_pixels.min(10000000)\n",
    "    # best_effort = ee.Algorithms.If(image_pixels.gt(max_pixels), True, False)\n",
    "    \n",
    "    # Set default projection and scale using the response band\n",
    "    defaultScale = image.select(defaultBand).projection().nominalScale()\n",
    "    defaultCrs = image.select(defaultBand).projection().crs()\n",
    "    image = image.setDefaultProjection(crs=defaultCrs, scale=defaultScale)\n",
    "    \n",
    "    # Initial centering all of the input bands, added VIs, and response with the input image\n",
    "    meanImage = image.subtract(image.reduceRegion(reducer=ee.Reducer.mean(), scale=defaultScale, bestEffort=True, maxPixels=max_pixels).toImage(bandList))\n",
    "    \n",
    "    # Separating the image into features (X) and response (y) for processing with LARs\n",
    "    X = meanImage.select(featureList)\n",
    "    y = meanImage.select(response_band)\n",
    "    \n",
    "    # Standardizing the input features\n",
    "    X = X.divide(X.reduceRegion(reducer=ee.Reducer.stdDev(), bestEffort=True, maxPixels=max_pixels).toImage(featureList))\n",
    "    \n",
    "    return X.addBands(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "scaledImage = scale_image(inputImage, defaultBand)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "'''\n",
    "def image2collection(image, num_samples):\n",
    "    image = ee.Image(image)\n",
    "    num_samples = ee.Number(num_samples)\n",
    "    image_pixels = ee.Number(get_num_pixels(image))\n",
    "    n = num_samples.min(image_pixels)\n",
    "    \n",
    "    # Extracting the image into arrays\n",
    "    inputsCollection = image.sample(None, None, None, None, n, 0, True, 1, True)\n",
    "    \n",
    "    return inputsCollection\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ndef image2collection(image, num_samples):\\n    image = ee.Image(image)\\n    num_samples = ee.Number(num_samples)\\n    image_pixels = ee.Number(get_num_pixels(image))\\n    n = num_samples.min(image_pixels)\\n    \\n    # Extracting the image into arrays\\n    inputsCollection = image.sample(None, None, None, None, n, 0, True, 1, True)\\n    \\n    return inputsCollection\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# inputsCollection = image2collection(scaledImage, 10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Export.table.toDrive({\n",
    "#     collection: inputsCollection,\n",
    "#     description: 'untrimmed_image_samples',\n",
    "#     fileFormat: 'CSV',\n",
    "#     selectors: ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12', 'B13',\n",
    "#                 \"GI\", \"RVI3\", \"SR3\", \"GM1\", \"GM2\", \"SR2\", \"PSSR\", \"SGI\", \"MSI\", \"II\", \"GVI\", \"PSRI\", \"NDVI3\",\n",
    "#                 \"SR5\", \"SR6\", \"SR7\", \"IPVI\", \"ARI\", \"ARI2\", \"NDVI\", \"GNDVI\", \"NDWI\", \"NDREVI\", \"NDGI\", \"NDI1\",\n",
    "#                 \"NDI2\", \"RENDVI\", \"OSAVI\", \"NMDI\", \"HI\", \"GVSP\", \"MCARI\", \"TCARI\", \"EVI\", \"EVI2\",\"RDVI\", \"MSR\",\n",
    "#                 \"MSAVI\", \"MSAVI2\", \"MCARI2\", \"MTVI2\", \"MSR2\", \"NLI\", \"LAI\"]\n",
    "#  })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def EE_LARS(image, response_band, num_nonzero_coefficients, num_samples):\n",
    "    image = ee.Image(image)\n",
    "    response_band = ee.String(response_band)\n",
    "    num_nonzero_coefficients = ee.Number(num_nonzero_coefficients)\n",
    "    num_samples = ee.Number(num_samples)\n",
    "    bandList = image.bandNames()\n",
    "    featureList = bandList.remove(response_band)\n",
    "    image_pixels = get_num_pixels(image)\n",
    "    inputCollection = image.sample(None, None, None, None, num_samples.min(image_pixels), 0, True, 1, True)\n",
    "    \n",
    "    n = inputCollection.size()\n",
    "    m = featureList.length()\n",
    "    \n",
    "    inputs = ee.Dictionary.fromLists(bandList, bandList.map(lambda feature: inputCollection.aggregate_array(feature)))\n",
    "    \n",
    "    # Re-centering the features and response as reduceRegion() is not as precise as centering with arrays \n",
    "    input_means = ee.Dictionary.fromLists(bandList, bandList.map(lambda feature: inputCollection.aggregate_mean(feature)))\n",
    "    \n",
    "    def center_inputs(key, value):\n",
    "        key_mean = input_means.getNumber(key)\n",
    "        return ee.List(value).map(lambda sample: ee.Number(sample).subtract(key_mean))\n",
    "    \n",
    "    inputs = inputs.map(center_inputs)\n",
    "    y = inputs.toArray([response_band]).reshape([-1,1])\n",
    "\n",
    "    # Re-normalizing the input features as reduceRegion() is not as precise as normalizing with arrays\n",
    "    inputs = inputs.select(featureList)\n",
    "    input_norms = inputs.map(lambda key, value: ee.Number(ee.List(value).map(lambda sample: ee.Number(sample).pow(2)).reduce(ee.Reducer.sum())).pow(0.5))\n",
    "    \n",
    "    def norm_inputs(key, value):\n",
    "        key_norm = input_norms.getNumber(key)\n",
    "        return ee.List(value).map(lambda sample: ee.Number(sample).divide(key_norm))\n",
    "    \n",
    "    inputs = inputs.map(norm_inputs)\n",
    "    X = inputs.toArray(featureList).transpose()\n",
    "    \n",
    "    # Find the first most correlated variable to pass into the main loop\n",
    "    initial_prediction = ee.Array(ee.List.repeat([0], n))\n",
    "    c = X.transpose().matrixMultiply(y.subtract(initial_prediction))\n",
    "    c_abs = c.abs()\n",
    "    C_maxLoc = c_abs.project([0]).argmax()\n",
    "    add_feature = C_maxLoc.getNumber(0)\n",
    "    A = ee.List([add_feature])\n",
    "    \n",
    "    initial_inputs = ee.Dictionary({'prediction': initial_prediction, 'A': A})\n",
    "    # print(A.getInfo())\n",
    "    # print(initial_inputs.getInfo())\n",
    "    \n",
    "    # Main loop\n",
    "    def LARs_regression(iteration, inputs):\n",
    "        inputs = ee.Dictionary(inputs)\n",
    "        A = ee.List(inputs.get('A'))\n",
    "        A_list = ee.Array(ee.List.sequence(0, m.subtract(1)).map(lambda index: A.contains(index))\\\n",
    "                          .replaceAll(False, 0).replaceAll(True ,1)).reshape([-1,1])\n",
    "\n",
    "        prediction = inputs.getArray('prediction')\n",
    "        c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "        c_abs = c.abs()\n",
    "        C_max = c_abs.get(c_abs.argmax())\n",
    "\n",
    "        s_A = c.divide(c_abs).mask(A_list)\n",
    "        X_A = X.mask(A_list.transpose())\n",
    "        G_Ai = X_A.transpose().matrixMultiply(X_A).matrixInverse()\n",
    "        G1 = G_Ai.matrixMultiply(s_A)\n",
    "        A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "        w_A = G1.multiply(A_A)\n",
    "        u_A = X_A.matrixMultiply(w_A)\n",
    "        a = X.transpose().matrixMultiply(u_A)\n",
    "\n",
    "        a = a.project([0])\n",
    "        c = c.project([0])\n",
    "        \n",
    "        def compute_gammaArray(index_j):\n",
    "            minus_j = C_max.subtract(c.get([index_j])).divide(A_A.subtract(a.get([index_j])))\n",
    "            plus_j = C_max.add(c.get([index_j])).divide(A_A.add(a.get([index_j])))\n",
    "            return ee.List([minus_j, plus_j]).filter(ee.Filter.gte('item', 0)).reduce(ee.Reducer.min())\n",
    "    \n",
    "        A_c = ee.List.sequence(0, m.subtract(1)).removeAll(A)\n",
    "        gammaArray = A_c.map(compute_gammaArray)\n",
    "        gamma = gammaArray.reduce(ee.Reducer.min())\n",
    "        min_location = gammaArray.indexOf(gamma)\n",
    "        add_feature = A_c.getNumber(min_location)\n",
    "        A = A.add(add_feature)\n",
    "        prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "        return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "\n",
    "    def LARs_final_iteration(iteration, inputs):\n",
    "        inputs = ee.Dictionary(inputs)\n",
    "        A = ee.List(inputs.get('A'))\n",
    "\n",
    "        prediction = inputs.getArray('prediction')\n",
    "        c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "        c_abs = c.abs()\n",
    "        C_max = c_abs.get(c_abs.argmax())\n",
    "\n",
    "        s_A = c.divide(c_abs)\n",
    "        G_Ai = X.transpose().matrixMultiply(X).matrixInverse()\n",
    "        G1 = G_Ai.matrixMultiply(s_A)\n",
    "        A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "        w_A = G1.multiply(A_A)\n",
    "        u_A = X.matrixMultiply(w_A)\n",
    "\n",
    "        gamma = C_max.divide(A_A)\n",
    "        prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "        return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "    \n",
    "    iterations = ee.List.sequence(1, m.subtract(1).min(num_nonzero_coefficients))\n",
    "    penultimate_outputs = iterations.iterate(LARs_regression, initial_inputs)\n",
    "    final_outputs = ee.Dictionary(ee.Algorithms.If(num_nonzero_coefficients.gte(m), \n",
    "                                                      LARs_final_iteration(m, penultimate_outputs),\n",
    "                                                      penultimate_outputs))\n",
    "    \n",
    "    final_prediction = final_outputs.getArray('prediction')\n",
    "    A = ee.List(final_outputs.get('A'))\n",
    "    feature_path = A.slice(0, num_nonzero_coefficients).map(lambda index: featureList.getString(index))\n",
    "    \n",
    "    coefficients = X.matrixSolve(final_prediction)\n",
    "    \n",
    "    def set_zero(num):\n",
    "        num = ee.Number(num)\n",
    "        return ee.Algorithms.If(num.abs().lt(0.001), 0, num)\n",
    "    \n",
    "    coefficients = coefficients.project([0]).toList().map(lambda num: set_zero(num))\n",
    "    # print('Coefficients', ee.Dictionary.fromLists(featureList, coefficients))\n",
    "    \n",
    "    return feature_path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "select_features = ee.List(EE_LARS(scaledImage, defaultBand, 5, 10000)).sort()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# The following function trims input data according to an algorithm in which the response band is partitioned into n equally sized\n",
    "# partitions, and in each of the n partitions, for the features selected by LARs, they are each trimmed individually down to only the\n",
    "# 5-95 percentile of the data. We are not doing any preprocessing with the data, so the raw data is exported from Earth Engine\n",
    "# The function takes an image, a list of strings with the selected feature bands in the image, the string that is the name of the response\n",
    "# band in this image, the number of samples/pixels the user wants to take from the image, and the number of parititions to trim within\n",
    "def trim_data(image, selected_features, response_band, num_samples, num_partitions):\n",
    "    image = ee.Image(image)\n",
    "    selected_features = ee.List(selected_features)\n",
    "    response_band = ee.String(response_band)\n",
    "    num_samples = ee.Number(num_samples)\n",
    "    num_partitions = ee.Number(num_partitions)\n",
    "    \n",
    "    # Generate the list of percentile bounds for the requested number of partitions, and the names of the value bounds for the\n",
    "    # dictionary that will be generated from the percentile reducer used later on\n",
    "    percentiles = ee.List.sequence(0, 100, ee.Number(100).divide(num_partitions))\n",
    "    percentile_names = percentiles.map(lambda num: ee.Number(num).round().toInt().format(\"p%s\"))\n",
    "\n",
    "    # Randomly sample the pixels in the input image into a feature collection containing only the selected features and the response\n",
    "    image_pixels = ee.Number(get_num_pixels(image))\n",
    "    inputsCollection = image.select(selected_features.add(response_band)).sample(numPixels=num_samples.min(image_pixels))\n",
    "\n",
    "    # Find the values at the percentile bounds using the percentile reducer over the feature collection\n",
    "    response_percentiles = inputsCollection.reduceColumns(ee.Reducer.percentile(percentiles=percentiles, outputNames=percentile_names, maxRaw=inputsCollection.size()), [response_band])\n",
    "    \n",
    "    # Create a list of percentile bounds for each partition\n",
    "    response_partitions = response_percentiles.values(percentile_names.remove('p100')).zip(response_percentiles.values(percentile_names.remove('p0')))\n",
    "    \n",
    "    def partition_data(partition_range):\n",
    "        partition_range = ee.List(partition_range)\n",
    "        return inputsCollection.filter(ee.Filter.rangeContains(response_band, partition_range.getNumber(0), partition_range.getNumber(1)))\n",
    "    \n",
    "    partitioned_data = response_partitions.map(partition_data)\n",
    "\n",
    "    # The following function now trims the data in each partition individually for each feature to its 5-95 percentile only\n",
    "    def trim_partitions(partition):\n",
    "        partition = ee.FeatureCollection(partition)\n",
    "        feature_trimming_bounds = selected_features.map(lambda feature: ee.List([feature]).cat(partition.reduceColumns(ee.Reducer.percentile([5, 95]), [feature]).values(['p5','p95'])))\n",
    "        def trimmer(current_feature, collection):\n",
    "            current_feature = ee.List(current_feature)\n",
    "            collection = ee.FeatureCollection(collection)\n",
    "            return collection.filter(ee.Filter.rangeContains(current_feature.getString(0), current_feature.getNumber(1), current_feature.getNumber(2)))\n",
    "        return feature_trimming_bounds.iterate(trimmer, partition)\n",
    "    \n",
    "    # Retrieve the trimmed data partitions and flatten the paritions into a single trimmed feature collection\n",
    "    trimmed_partitions = partitioned_data.map(trim_partitions)\n",
    "    trimmed_data = ee.FeatureCollection(trimmed_partitions).flatten()\n",
    "    \n",
    "    return trimmed_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "trimmedCollection = trim_data(image=inputImage.updateMask(inputImage.select(defaultBand).gt(0)), \\\n",
    "                    selected_features=select_features, response_band=defaultBand, num_samples=5000, num_partitions=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "exportData = ee.batch.Export.table.toDrive(collection=trimmedCollection, description='image_samples', fileFormat='CSV')\n",
    "exportData.start()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Essentially a wait loop to see if the data has finished exporting by checking with the server-side\n",
    "prev_task_status = ee.data.getTaskStatus(exportData.id)[0][\"state\"]\n",
    "print(prev_task_status)\n",
    "while exportData.active():\n",
    "    task_status = ee.data.getTaskStatus(exportData.id)[0][\"state\"]\n",
    "    if(task_status != prev_task_status):\n",
    "        print(task_status)\n",
    "    prev_task_status = task_status\n",
    "    time.sleep(5)\n",
    "print(ee.data.getTaskStatus(exportData.id)[0][\"state\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "READY\n",
      "RUNNING\n",
      "COMPLETED\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "nnet = ee.FeatureCollection(\"users/hemitshah/nnet5\")\n",
    "nnet_inputs = nnet.filter(ee.Filter.eq(\"layer_num\", 0)).first()\n",
    "num_inputs = nnet_inputs.getNumber(\"num_nodes\")\n",
    "\n",
    "selected_features = nnet_inputs.getString(\"activation\").split(\",\")\n",
    "\n",
    "nnet = nnet.filterBounds(ee.Geometry.Point([0,0]))\n",
    "layer_list = nnet.sort(\"layer_num\").toList(nnet.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def parse_layer(feature):\n",
    "    feature = ee.Feature(feature)\n",
    "    prev_layer_size = feature.getNumber(\"prev_layer_size\")\n",
    "    num_nodes = feature.getNumber(\"num_nodes\")\n",
    "    node_size = prev_layer_size.subtract(1)\n",
    "    activation = feature.getString(\"activation\")\n",
    "    \n",
    "    node_collection = ee.ImageCollection(ee.List.sequence(1, num_nodes)\\\n",
    "                        .map(lambda node: ee.ImageCollection(ee.List.sequence(ee.Number(node).toInt(), ee.Number(node)\\\n",
    "                                    .toInt().add(node_size.multiply(num_nodes)), num_nodes)\\\n",
    "                        .map(lambda index: ee.Image(feature.getNumber(ee.Number(index).toInt())))).toBands()\\\n",
    "                        .set({\"bias\": feature.getNumber(ee.Number(node).toInt().add(prev_layer_size.multiply(num_nodes)))})))\n",
    "    \n",
    "    return ee.List([node_collection, activation])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "neural_net = layer_list.map(parse_layer)\n",
    "'''\n",
    "print(ee.List(neural_net.get(0)).get(0))\n",
    "print(ee.List(neural_net.get(0)).get(1))\n",
    "print(ee.List(neural_net.get(1)).get(0))\n",
    "print(ee.List(neural_net.get(1)).get(1))\n",
    "print(ee.List(neural_net.get(2)).get(0))\n",
    "print(ee.List(neural_net.get(2)).get(1))\n",
    "print(ee.List(neural_net.get(3)).get(0))\n",
    "print(ee.List(neural_net.get(3)).get(1))\n",
    "print(ee.List(neural_net.get(4)).get(0))\n",
    "print(ee.List(neural_net.get(4)).get(1))\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nprint(ee.List(neural_net.get(0)).get(0))\\nprint(ee.List(neural_net.get(0)).get(1))\\nprint(ee.List(neural_net.get(1)).get(0))\\nprint(ee.List(neural_net.get(1)).get(1))\\nprint(ee.List(neural_net.get(2)).get(0))\\nprint(ee.List(neural_net.get(2)).get(1))\\nprint(ee.List(neural_net.get(3)).get(0))\\nprint(ee.List(neural_net.get(3)).get(1))\\nprint(ee.List(neural_net.get(4)).get(0))\\nprint(ee.List(neural_net.get(4)).get(1))\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def linear(x):\n",
    "    return ee.Image(x)\n",
    "\n",
    "def elu(x):\n",
    "    x = ee.Image(x)\n",
    "    return ee.ImageCollection([x.mask(x.gte(0)), x.mask(x.lt(0)).exp().subtract(1)]).mosaic()\n",
    "\n",
    "def softplus(x):\n",
    "    x = ee.Image(x)\n",
    "    return x.exp().add(1).log()\n",
    "\n",
    "def softsign(x):\n",
    "    x = ee.Image(x)\n",
    "    return x.divide(x.abs().add(1))\n",
    "\n",
    "def relu(x):\n",
    "    x = ee.Image(x)\n",
    "    return x.max(0.0)\n",
    "\n",
    "def tanh(x):\n",
    "    x = ee.Image(x)\n",
    "    return x.multiply(2).exp().subtract(1).divide(x.multiply(2).exp().add(1))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return x.exp().pow(-1).add(1).pow(-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def apply_nnet(layer, net_input):\n",
    "    layer = ee.List(layer)\n",
    "    net_input = ee.Image(net_input)\n",
    "    \n",
    "    layer_nodes = ee.ImageCollection(layer.get(0))\n",
    "    activation = layer.getString(1)\n",
    "    \n",
    "    node_outputs = layer_nodes.map(lambda node: ee.Algorithms.If(activation.compareTo(\"linear\"), \\\n",
    "                        softsign(net_input.multiply(node).reduce(ee.Reducer.sum()).add(node.getNumber(\"bias\"))), \\\n",
    "                        net_input.multiply(ee.Image(node)).reduce(ee.Reducer.sum()).add(ee.Image(node).getNumber(\"bias\")))).toBands()\n",
    "\n",
    "    return node_outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "validation_data = inputImage.select(\"LAI\")\n",
    "nnet_inputs = scaledImage.select(selected_features)\n",
    "# layer1out = apply_nnet(neural_net.get(0), nnet_inputs)\n",
    "# layer2out = apply_nnet(neural_net.get(1), layer1out)\n",
    "# layer3out = apply_nnet(neural_net.get(2), layer2out)\n",
    "# layer4out = apply_nnet(neural_net.get(3), layer3out)\n",
    "# layer5out = apply_nnet(neural_net.get(4), layer4out)\n",
    "# Map.addLayer(layer1out)\n",
    "# Map.addLayer(layer2out)\n",
    "# Map.addLayer(layer3out)\n",
    "# Map.addLayer(layer4out)\n",
    "# Map.addLayer(layer5out)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "prediction_data = ee.Image(neural_net.iterate(apply_nnet, nnet_inputs)).rename(\"NNET\")\n",
    "inputsCollection = ee.FeatureCollection(\"users/hemitshah/image_data_samples\").select(selected_features.add(\"LAI\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "ee_regressor = ee.Classifier.smileRandomForest(numberOfTrees=100,\n",
    "                                               variablesPerSplit=0,\n",
    "                                               minLeafPopulation=3,\n",
    "                                               bagFraction=0.1, seed=0).setOutputMode(\"REGRESSION\")\\\n",
    "                .train(features=inputsCollection, classProperty=\"LAI\", inputProperties=selected_features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "ee_prediction = nnet_inputs.addBands(validation_data).classify(ee_regressor, \"RANDOM_FOREST\")\n",
    "# Map.addLayer(validation_data)\n",
    "# Map.addLayer(prediction_data)\n",
    "# Map.addLayer(ee_prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "nnet_rmse = prediction_data.subtract(validation_data).pow(2).reduceRegion(ee.Reducer.mean(), None, None, None, None, True, 10000000, 1).values().getNumber(0).pow(0.5)\n",
    "rf_rmse = ee_prediction.subtract(validation_data).pow(2).reduceRegion(ee.Reducer.mean(), None, None, None, None, True, 10000000, 1).values().getNumber(0).pow(0.5)\n",
    "# print(\"NEURAL NET RMSE: \", nnet_rmse)\n",
    "# print(\"RANDOM FOREST RMSE: \", rf_rmse)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}